{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-aUoZ41RNp9",
        "outputId": "2f06bb61-5818-4d52-a2bd-a56dbaec201c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Se da acceso a la base de datos que se encuentra en la nube\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pja7vekKRcd-"
      },
      "outputs": [],
      "source": [
        "pathTest = '/content/drive/Othercomputers/Mi portátil/2023-1/Trabajo de grado/Base de datos/Segmented/Pacientes por género/Test/'\n",
        "pathTrain = '/content/drive/Othercomputers/Mi portátil/2023-1/Trabajo de grado/Base de datos/Segmented/Pacientes por género/Train/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggkOq5lfwLM3",
        "outputId": "95670284-010c-4cd3-a058-0dcbaea9a513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.2.0-py3-none-any.whl (390 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.6/390.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.11.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmaes>=0.9.1 (from optuna)\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.65.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n",
            "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.11.1 cmaes-0.9.1 colorlog-6.7.0 optuna-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wrappers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Md-eYn32wYBt",
        "outputId": "644a2d10-a1f8-4f86-ac09-174d71f1236d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wrappers\n",
            "  Downloading wrappers-0.1.9.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  WARNING: Generating metadata for package wrappers produced metadata for project name wrappers-ba663bc055384e30977f9017abffba98. Fix your #egg=wrappers fragments.\u001b[0m\u001b[33m\n",
            "\u001b[0mDiscarding \u001b[4;34mhttps://files.pythonhosted.org/packages/81/fd/e3859be14b9feda7e11c719d7ffc5288e73664f9224be71fdb97cbd2d4ee/wrappers-0.1.9.tar.gz (from https://pypi.org/simple/wrappers/)\u001b[0m: \u001b[33mRequested wrappers-ba663bc055384e30977f9017abffba98 from https://files.pythonhosted.org/packages/81/fd/e3859be14b9feda7e11c719d7ffc5288e73664f9224be71fdb97cbd2d4ee/wrappers-0.1.9.tar.gz has inconsistent name: expected 'wrappers', but metadata has 'wrappers-ba663bc055384e30977f9017abffba98'\u001b[0m\n",
            "  Downloading wrappers-0.1.8.tar.gz (2.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  WARNING: Generating metadata for package wrappers produced metadata for project name wrappers-88cb2844ccce476e89c3e3915958fecf. Fix your #egg=wrappers fragments.\u001b[0m\u001b[33m\n",
            "\u001b[0mDiscarding \u001b[4;34mhttps://files.pythonhosted.org/packages/a6/8b/631b7d172369efdb26fd34adb2f56233da40665b7b4e99dac11846b154fd/wrappers-0.1.8.tar.gz (from https://pypi.org/simple/wrappers/)\u001b[0m: \u001b[33mRequested wrappers-88cb2844ccce476e89c3e3915958fecf from https://files.pythonhosted.org/packages/a6/8b/631b7d172369efdb26fd34adb2f56233da40665b7b4e99dac11846b154fd/wrappers-0.1.8.tar.gz has inconsistent name: expected 'wrappers', but metadata has 'wrappers-88cb2844ccce476e89c3e3915958fecf'\u001b[0m\n",
            "  Downloading wrappers-0.1.7.tar.gz (2.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  WARNING: Generating metadata for package wrappers produced metadata for project name wrappers-05b46f9c77944bac8ffd2160652798af. Fix your #egg=wrappers fragments.\u001b[0m\u001b[33m\n",
            "\u001b[0mDiscarding \u001b[4;34mhttps://files.pythonhosted.org/packages/e1/ae/98430d91b8c229ae7b8967c03ab32aceb3ff839db07ec806d6e64a436da4/wrappers-0.1.7.tar.gz (from https://pypi.org/simple/wrappers/)\u001b[0m: \u001b[33mRequested wrappers-05b46f9c77944bac8ffd2160652798af from https://files.pythonhosted.org/packages/e1/ae/98430d91b8c229ae7b8967c03ab32aceb3ff839db07ec806d6e64a436da4/wrappers-0.1.7.tar.gz has inconsistent name: expected 'wrappers', but metadata has 'wrappers-05b46f9c77944bac8ffd2160652798af'\u001b[0m\n",
            "  Downloading wrappers-0.1.6.tar.gz (2.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  WARNING: Generating metadata for package wrappers produced metadata for project name wrappers-9270d0e8b544427ebbd8f90bc16392c8. Fix your #egg=wrappers fragments.\u001b[0m\u001b[33m\n",
            "\u001b[0mDiscarding \u001b[4;34mhttps://files.pythonhosted.org/packages/33/b5/fbea2030284f986dfbf56056c87a8b85de4de12bf91cacc1eefee4734bec/wrappers-0.1.6.tar.gz (from https://pypi.org/simple/wrappers/)\u001b[0m: \u001b[33mRequested wrappers-9270d0e8b544427ebbd8f90bc16392c8 from https://files.pythonhosted.org/packages/33/b5/fbea2030284f986dfbf56056c87a8b85de4de12bf91cacc1eefee4734bec/wrappers-0.1.6.tar.gz has inconsistent name: expected 'wrappers', but metadata has 'wrappers-9270d0e8b544427ebbd8f90bc16392c8'\u001b[0m\n",
            "  Downloading wrappers-0.1.5.tar.gz (2.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  WARNING: Generating metadata for package wrappers produced metadata for project name wrappers-d2f189f33c85465181401e63b2f1ab09. Fix your #egg=wrappers fragments.\u001b[0m\u001b[33m\n",
            "\u001b[0mDiscarding \u001b[4;34mhttps://files.pythonhosted.org/packages/2d/06/28d9a55644b912d91ac4c0ed2ef0ee3f718bf2cc32188bf213575e7d0666/wrappers-0.1.5.tar.gz (from https://pypi.org/simple/wrappers/)\u001b[0m: \u001b[33mRequested wrappers-d2f189f33c85465181401e63b2f1ab09 from https://files.pythonhosted.org/packages/2d/06/28d9a55644b912d91ac4c0ed2ef0ee3f718bf2cc32188bf213575e7d0666/wrappers-0.1.5.tar.gz has inconsistent name: expected 'wrappers', but metadata has 'wrappers-d2f189f33c85465181401e63b2f1ab09'\u001b[0m\n",
            "  Downloading wrappers-0.1.4.tar.gz (2.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  WARNING: Generating metadata for package wrappers produced metadata for project name wrappers-e93014f9b489498692e6ea569733e259. Fix your #egg=wrappers fragments.\u001b[0m\u001b[33m\n",
            "\u001b[0mDiscarding \u001b[4;34mhttps://files.pythonhosted.org/packages/b5/47/43bd479eaecb30ee80f0b2d2a7e9e74d6208380a8d1cf75c13a8237e94d2/wrappers-0.1.4.tar.gz (from https://pypi.org/simple/wrappers/)\u001b[0m: \u001b[33mRequested wrappers-e93014f9b489498692e6ea569733e259 from https://files.pythonhosted.org/packages/b5/47/43bd479eaecb30ee80f0b2d2a7e9e74d6208380a8d1cf75c13a8237e94d2/wrappers-0.1.4.tar.gz has inconsistent name: expected 'wrappers', but metadata has 'wrappers-e93014f9b489498692e6ea569733e259'\u001b[0m\n",
            "  Downloading wrappers-0.1.3.tar.gz (2.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  WARNING: Generating metadata for package wrappers produced metadata for project name wrappers-f55a9df780e7468a8ebc1e04a213ba11. Fix your #egg=wrappers fragments.\u001b[0m\u001b[33m\n",
            "\u001b[0mDiscarding \u001b[4;34mhttps://files.pythonhosted.org/packages/c4/bb/066bb20d15b646bedff07386e114965e661e5f3e7a7723912eeb0f1b7d87/wrappers-0.1.3.tar.gz (from https://pypi.org/simple/wrappers/)\u001b[0m: \u001b[33mRequested wrappers-f55a9df780e7468a8ebc1e04a213ba11 from https://files.pythonhosted.org/packages/c4/bb/066bb20d15b646bedff07386e114965e661e5f3e7a7723912eeb0f1b7d87/wrappers-0.1.3.tar.gz has inconsistent name: expected 'wrappers', but metadata has 'wrappers-f55a9df780e7468a8ebc1e04a213ba11'\u001b[0m\n",
            "  Downloading wrappers-0.1.2.tar.gz (2.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  WARNING: Generating metadata for package wrappers produced metadata for project name wrappers-e37bd1ebf8844a979b184f460ecc5c14. Fix your #egg=wrappers fragments.\u001b[0m\u001b[33m\n",
            "\u001b[0mDiscarding \u001b[4;34mhttps://files.pythonhosted.org/packages/e4/a8/777aaa9d642ec078dd8773210680b586690261ccb83785d2e32afa9e7b06/wrappers-0.1.2.tar.gz (from https://pypi.org/simple/wrappers/)\u001b[0m: \u001b[33mRequested wrappers-e37bd1ebf8844a979b184f460ecc5c14 from https://files.pythonhosted.org/packages/e4/a8/777aaa9d642ec078dd8773210680b586690261ccb83785d2e32afa9e7b06/wrappers-0.1.2.tar.gz has inconsistent name: expected 'wrappers', but metadata has 'wrappers-e37bd1ebf8844a979b184f460ecc5c14'\u001b[0m\n",
            "  Downloading wrappers-0.1.1.tar.gz (2.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  WARNING: Generating metadata for package wrappers produced metadata for project name wrappers-5cedccf7fb4a4de69eed9c0259d7cb26. Fix your #egg=wrappers fragments.\u001b[0m\u001b[33m\n",
            "\u001b[0mDiscarding \u001b[4;34mhttps://files.pythonhosted.org/packages/11/6a/b344909cb0149b1e74e51acacf463a7daa40f1697881f726c214731b675a/wrappers-0.1.1.tar.gz (from https://pypi.org/simple/wrappers/)\u001b[0m: \u001b[33mRequested wrappers-5cedccf7fb4a4de69eed9c0259d7cb26 from https://files.pythonhosted.org/packages/11/6a/b344909cb0149b1e74e51acacf463a7daa40f1697881f726c214731b675a/wrappers-0.1.1.tar.gz has inconsistent name: expected 'wrappers', but metadata has 'wrappers-5cedccf7fb4a4de69eed9c0259d7cb26'\u001b[0m\n",
            "  Downloading wrappers-0.1.0.tar.gz (2.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  WARNING: Generating metadata for package wrappers produced metadata for project name wrappers-04ee25c8858747c1b03e6c323f13125c. Fix your #egg=wrappers fragments.\u001b[0m\u001b[33m\n",
            "\u001b[0mDiscarding \u001b[4;34mhttps://files.pythonhosted.org/packages/0d/6c/f2c87d7550f306d99875b487d5cb391aff2440404d64fd3853e840016a66/wrappers-0.1.0.tar.gz (from https://pypi.org/simple/wrappers/)\u001b[0m: \u001b[33mRequested wrappers-04ee25c8858747c1b03e6c323f13125c from https://files.pythonhosted.org/packages/0d/6c/f2c87d7550f306d99875b487d5cb391aff2440404d64fd3853e840016a66/wrappers-0.1.0.tar.gz has inconsistent name: expected 'wrappers', but metadata has 'wrappers-04ee25c8858747c1b03e6c323f13125c'\u001b[0m\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement wrappers (from versions: 0.1.0, 0.1.1, 0.1.2, 0.1.3, 0.1.4, 0.1.5, 0.1.6, 0.1.7, 0.1.8, 0.1.9)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for wrappers\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-esfSewuReXe"
      },
      "outputs": [],
      "source": [
        "#Importar las librerías necesarias\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from scipy.io import loadmat\n",
        "from scipy.signal import spectrogram\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import TimeDistributed\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.signal as signal\n",
        "import optuna\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##############################Cargar las matrices por gesto TRAIN#######################################\n",
        "# Listado de nombres de archivos .mat que quieres cargar\n",
        "nombres_archivos = ['Reposo', 'Extension', 'Flexion','DesvCubital', 'DesvRadial', 'Agarre','Abduccion', 'Aduccion', 'Supinacion','Pronacion']\n",
        "matrices_normalizadas_train = []\n",
        "\n",
        "# Carga los archivos .mat y realiza la normalización de las matrices con z-score\n",
        "for nombre_archivo in nombres_archivos:\n",
        "    nombre_mat = nombre_archivo+'.mat'\n",
        "    ruta_archivo = os.path.join(pathTrain, nombre_mat)  # Ruta completa del archivo\n",
        "    data = loadmat(ruta_archivo)\n",
        "    datos = data[nombre_archivo]\n",
        "    datos = datos[:,[0,2]] #Se cargan los canales 1 y 3\n",
        "    \n",
        "    # Calcular la media y la desviación estándar a lo largo del eje deseado (por ejemplo, eje 0)\n",
        "    media = np.mean(datos, axis=0)\n",
        "    desviacion_estandar = np.std(datos, axis=0)\n",
        "    \n",
        "    # Normalizar los datos utilizando z-score\n",
        "    datos_normalizados = (datos - media) / desviacion_estandar\n",
        "    \n",
        "    #Almacenar las matrices resultantes en una lista\n",
        "    matrices_normalizadas_train.append(datos_normalizados)"
      ],
      "metadata": {
        "id": "2aEKx2gWf9vZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Se verifica que todas las matrices resultantes tengan los tamaños correspondientes\n",
        "def obtener_tamanos_matrices(lista_matrices):\n",
        "    tamanos = []\n",
        "    for matriz in lista_matrices:\n",
        "        tamanos.append(matriz.shape)\n",
        "    return tamanos\n",
        "\n",
        "tamanos = obtener_tamanos_matrices(matrices_normalizadas_train)\n",
        "print(tamanos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFL-N1SDkano",
        "outputId": "521e6523-66d8-4877-9584-ff946d7c648a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(1920000, 2), (1920000, 2), (1920000, 2), (1920000, 2), (1920000, 2), (1920000, 2), (1920000, 2), (1920000, 2), (1920000, 2), (1920000, 2)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crea una lista para almacenar los espectrogramas apilados de cada gesto\n",
        "stacked_spectrograms_train = []\n",
        "\n",
        "# Parámetros de la ventana deslizante\n",
        "window_size = 600  # Tamaño de la ventana deslizante\n",
        "overlap = 0.5  # Superposición entre ventanas (50%)\n",
        "\n",
        "for gesture_matrix in matrices_normalizadas_train:\n",
        "    # Obtén las dimensiones de los espectrogramas\n",
        "    num_spectrograms = int(np.floor((gesture_matrix.shape[0] - window_size) / (window_size * (1 - overlap)))) + 1\n",
        "    spectrogram_length = int(window_size / 2) + 1  # Longitud de los espectrogramas (la mitad de la ventana deslizante)\n",
        "\n",
        "    # Crea una matriz tridimensional para almacenar los espectrogramas apilados de un gesto\n",
        "    stacked_gesture_spectrograms = np.zeros((num_spectrograms, spectrogram_length, 2))\n",
        "\n",
        "    # Aplica ventanas deslizantes y calcula los espectrogramas\n",
        "    for i in range(num_spectrograms):\n",
        "        start = int(i * window_size * (1 - overlap))\n",
        "        end = start + window_size\n",
        "\n",
        "        # Aplica la ventana deslizante a las señales EMG\n",
        "        windowed_signals = gesture_matrix[start:end, :]\n",
        "\n",
        "        # Calcula los espectrogramas de cada canal\n",
        "        spectrogram_channel1 = signal.spectrogram(windowed_signals[:, 0], fs=2000, nperseg=window_size, noverlap=int(window_size * overlap))\n",
        "        spectrogram_channel2 = signal.spectrogram(windowed_signals[:, 1], fs=2000, nperseg=window_size, noverlap=int(window_size * overlap))\n",
        "\n",
        "        # Asigna los espectrogramas de cada canal a la matriz tridimensional\n",
        "        stacked_gesture_spectrograms[i, :, 0] = spectrogram_channel1[2].T  # Transpón el espectrograma\n",
        "        stacked_gesture_spectrograms[i, :, 1] = spectrogram_channel2[2].T\n",
        "\n",
        "    # Agrega la matriz apilada del gesto a la lista\n",
        "    stacked_spectrograms_train.append(stacked_gesture_spectrograms)\n",
        "\n",
        "# La lista stacked_spectrograms ahora contiene las matrices tridimensionales de los espectrogramas apilados de cada gesto\n",
        "# Cada elemento de la lista representa un gesto y tiene una forma (N, longitud_fija, 2), donde N es el número de espectrogramas y longitud_fija es la longitud común de los espectrogramas"
      ],
      "metadata": {
        "id": "PxPj52DQm00-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Se verifica que todas los espectrogramas tengan los tamaños correspondientes\n",
        "def obtener_tamanos_matrices(lista_matrices):\n",
        "    tamanos = []\n",
        "    for matriz in lista_matrices:\n",
        "        tamanos.append(matriz.shape)\n",
        "    return tamanos\n",
        "\n",
        "tamanos = obtener_tamanos_matrices(stacked_spectrograms_train)\n",
        "print(tamanos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8rbR0eZYnXI",
        "outputId": "2a3bb26d-cea5-437b-bd24-d2efa85d426e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(6399, 301, 2), (6399, 301, 2), (6399, 301, 2), (6399, 301, 2), (6399, 301, 2), (6399, 301, 2), (6399, 301, 2), (6399, 301, 2), (6399, 301, 2), (6399, 301, 2)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##############################Cargar las matrices por gesto TEST#######################################\n",
        "# Listado de nombres de archivos .mat que quieres cargar\n",
        "nombres_archivos = ['Reposo', 'Extension', 'Flexion','DesvCubital', 'DesvRadial', 'Agarre','Abduccion', 'Aduccion', 'Supinacion','Pronacion']\n",
        "matrices_normalizadas_test = []\n",
        "\n",
        "# Carga los archivos .mat y realiza la normalización de las matrices con z-score\n",
        "for nombre_archivo in nombres_archivos:\n",
        "    nombre_mat = nombre_archivo+'.mat'\n",
        "    ruta_archivo = os.path.join(pathTest, nombre_mat)  # Ruta completa del archivo\n",
        "    data = loadmat(ruta_archivo)\n",
        "    datos = data[nombre_archivo]\n",
        "    datos = datos[:,[0,2]] #Se cargan los canales 1 y 3\n",
        "    \n",
        "    # Calcular la media y la desviación estándar a lo largo del eje deseado (por ejemplo, eje 0)\n",
        "    media = np.mean(datos, axis=0)\n",
        "    desviacion_estandar = np.std(datos, axis=0)\n",
        "    \n",
        "    # Normalizar los datos utilizando z-score\n",
        "    datos_normalizados = (datos - media) / desviacion_estandar\n",
        "    \n",
        "    #Almacenar las matrices resultantes en una lista\n",
        "    matrices_normalizadas_test.append(datos_normalizados)"
      ],
      "metadata": {
        "id": "5pditGToEw6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Se verifica que todas las matrices resultantes tengan los tamaños correspondientes\n",
        "def obtener_tamanos_matrices(lista_matrices):\n",
        "    tamanos = []\n",
        "    for matriz in lista_matrices:\n",
        "        tamanos.append(matriz.shape)\n",
        "    return tamanos\n",
        "\n",
        "tamanos = obtener_tamanos_matrices(matrices_normalizadas_test)\n",
        "print(tamanos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qKokT2YE72h",
        "outputId": "b32a7502-cb98-42ed-b59c-edf533d04880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(480000, 2), (480000, 2), (480000, 2), (480000, 2), (480000, 2), (480000, 2), (480000, 2), (480000, 2), (480000, 2), (480000, 2)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crea una lista para almacenar los espectrogramas apilados de cada gesto\n",
        "stacked_spectrograms_test = []\n",
        "\n",
        "# Parámetros de la ventana deslizante\n",
        "window_size = 600  # Tamaño de la ventana deslizante\n",
        "overlap = 0.5  # Superposición entre ventanas (50%)\n",
        "\n",
        "for gesture_matrix in matrices_normalizadas_test:\n",
        "    # Obtén las dimensiones de los espectrogramas\n",
        "    num_spectrograms = int(np.floor((gesture_matrix.shape[0] - window_size) / (window_size * (1 - overlap)))) + 1\n",
        "    spectrogram_length = int(window_size / 2) + 1  # Longitud de los espectrogramas (la mitad de la ventana deslizante)\n",
        "\n",
        "    # Crea una matriz tridimensional para almacenar los espectrogramas apilados de un gesto\n",
        "    stacked_gesture_spectrograms = np.zeros((num_spectrograms, spectrogram_length, 2))\n",
        "\n",
        "    # Aplica ventanas deslizantes y calcula los espectrogramas\n",
        "    for i in range(num_spectrograms):\n",
        "        start = int(i * window_size * (1 - overlap))\n",
        "        end = start + window_size\n",
        "\n",
        "        # Aplica la ventana deslizante a las señales EMG\n",
        "        windowed_signals = gesture_matrix[start:end, :]\n",
        "\n",
        "        # Calcula los espectrogramas de cada canal\n",
        "        spectrogram_channel1 = signal.spectrogram(windowed_signals[:, 0], fs=2000, nperseg=window_size, noverlap=int(window_size * overlap))\n",
        "        spectrogram_channel2 = signal.spectrogram(windowed_signals[:, 1], fs=2000, nperseg=window_size, noverlap=int(window_size * overlap))\n",
        "\n",
        "        # Asigna los espectrogramas de cada canal a la matriz tridimensional\n",
        "        stacked_gesture_spectrograms[i, :, 0] = spectrogram_channel1[2].T  # Transpón el espectrograma\n",
        "        stacked_gesture_spectrograms[i, :, 1] = spectrogram_channel2[2].T\n",
        "\n",
        "    # Agrega la matriz apilada del gesto a la lista\n",
        "    stacked_spectrograms_test.append(stacked_gesture_spectrograms)\n",
        "\n",
        "# La lista stacked_spectrograms ahora contiene las matrices tridimensionales de los espectrogramas apilados de cada gesto\n",
        "# Cada elemento de la lista representa un gesto y tiene una forma (N, longitud_fija, 2), donde N es el número de espectrogramas y longitud_fija es la longitud común de los espectrogramas"
      ],
      "metadata": {
        "id": "qjfQ1JorFKfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Se verifica que todas los espectrogramas tengan los tamaños correspondientes\n",
        "def obtener_tamanos_matrices(lista_matrices):\n",
        "    tamanos = []\n",
        "    for matriz in lista_matrices:\n",
        "        tamanos.append(matriz.shape)\n",
        "    return tamanos\n",
        "\n",
        "tamanos = obtener_tamanos_matrices(stacked_spectrograms_test)\n",
        "print(tamanos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-D1b9hNEJUVW",
        "outputId": "cd985ff5-a069-489d-efe6-04b26971aa20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(1599, 301, 2), (1599, 301, 2), (1599, 301, 2), (1599, 301, 2), (1599, 301, 2), (1599, 301, 2), (1599, 301, 2), (1599, 301, 2), (1599, 301, 2), (1599, 301, 2)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apilar las matrices de espectrogramas en una sola matriz tridimensional para los datos de entrenamiento\n",
        "X_train = np.concatenate(stacked_spectrograms_train, axis=0)\n",
        "print(\"Dimensiones de X_train:\",X_train.shape)\n",
        "\n",
        "# Apilar las matrices de espectrogramas en una sola matriz tridimensional para los datos de prueba\n",
        "X_test = np.concatenate(stacked_spectrograms_test, axis=0)\n",
        "print(\"Dimensiones de X_test:\",X_test.shape)  # Verificar la forma de stacked_gestures_test\n",
        "\n",
        "T=X_train.shape[2]\n",
        "F=X_train.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3zX_iV1KOLm",
        "outputId": "b1ce71ec-1e46-499e-f758-eb22638c188a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensiones de X_train: (63990, 301, 2)\n",
            "Dimensiones de X_test: (15990, 301, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#seed = 42  # Set the desired seed value\n",
        "#np.random.seed(seed)  # Set the seed for random number generation\n",
        "#shape = X_train.shape\n",
        "#random_indices = np.random.permutation(shape[axis])\n",
        "#reordered_matrix = np.take(matrix, random_indices, axis=axis)"
      ],
      "metadata": {
        "id": "ycZAIqNKdhc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_etiquetas = 10  # Número de etiquetas a asignar\n",
        "muestras_por_etiqueta_train = 6399  # Número de muestras por etiqueta train\n",
        "muestras_por_etiqueta_test = 1599  # Número de muestras por etiqueta test\n",
        "\n",
        "# Codificar las etiquetas en formato one-hot\n",
        "y_train = np.repeat(np.arange(num_etiquetas), muestras_por_etiqueta_train)\n",
        "y_train = to_categorical(y_train, num_etiquetas)\n",
        "\n",
        "y_test = np.repeat(np.arange(num_etiquetas), muestras_por_etiqueta_test)\n",
        "y_test = to_categorical(y_test, num_etiquetas)\n",
        "\n",
        "# Verificar las dimensiones de y_train y y_test\n",
        "print(\"Dimensiones de y_train:\", y_train.shape)\n",
        "print(\"Dimensiones de y_test:\", y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Huy10XMUK4Hl",
        "outputId": "50213a8f-39b5-4036-fdd4-05ee728abe2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensiones de y_train: (63990, 10)\n",
            "Dimensiones de y_test: (15990, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmLkxyULgg0-"
      },
      "outputs": [],
      "source": [
        "#### Dividir datos de entrenamiento en entrenamiento y validación\n",
        "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJ8GJhioeG7j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae847cad-7425-49d9-d889-9df0f6c18498"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500/500 [==============================] - 132s 261ms/step\n",
            "Mejor resultado: 0.09993746091307067\n"
          ]
        }
      ],
      "source": [
        "# Función objetivo para la optimización de hiperparámetros\n",
        "def objective():\n",
        "    units_lstm = 128\n",
        "    units_oculta = 128\n",
        "    dropout = 0.5\n",
        "\n",
        "    modelo = Sequential()\n",
        "    modelo.add(Flatten())\n",
        "    modelo.add(Bidirectional(LSTM(units=units_lstm, return_sequences=True)))\n",
        "    modelo.add(BatchNormalization())\n",
        "    modelo.add(Dropout(dropout))\n",
        "    modelo.add(TimeDistributed(Dense(units=units_oculta, activation='relu')))\n",
        "    modelo.add(Flatten())\n",
        "    modelo.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "    modelo.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    es = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "    modelo.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32, callbacks=[es], verbose=0)\n",
        "\n",
        "    y_pred = modelo.predict(X_test)\n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "    accuracy = accuracy_score(np.argmax(y_test, axis=1), y_pred)\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Ejecutar la función objetivo sin optimización de hiperparámetros\n",
        "mejor_resultado = objective()\n",
        "\n",
        "print(\"Mejor resultado:\", mejor_resultado)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuración del PC para correr en local\n",
        "\n",
        "Shuffle \n",
        "\n",
        "Hiperparámetros"
      ],
      "metadata": {
        "id": "H29UtuIEhNNc"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}