{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-esfSewuReXe"
      },
      "outputs": [],
      "source": [
        "#Importar las librerías necesarias\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from scipy.io import loadmat\n",
        "from scipy.signal import spectrogram\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, Bidirectional, LSTM\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import TimeDistributed\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.signal as signal\n",
        "import optuna\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "pathTrain = \"Datasets\\Train\"\n",
        "pathTest = \"Datasets\\Test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2aEKx2gWf9vZ"
      },
      "outputs": [],
      "source": [
        "##############################Cargar las matrices por gesto TRAIN#######################################\n",
        "# Listado de nombres de archivos .mat que quieres cargar\n",
        "nombres_archivos = ['Reposo', 'Extension', 'Flexion','DesvCubital', 'DesvRadial', 'Agarre','Abduccion', 'Aduccion', 'Supinacion','Pronacion']\n",
        "matrices_normalizadas_train = []\n",
        "\n",
        "# Carga los archivos .mat y realiza la normalización de las matrices con z-score\n",
        "for nombre_archivo in nombres_archivos:\n",
        "    nombre_mat = nombre_archivo+'.mat'\n",
        "    ruta_archivo = os.path.join(pathTrain, nombre_mat)  # Ruta completa del archivo\n",
        "    data = loadmat(ruta_archivo)\n",
        "    datos = data[nombre_archivo]\n",
        "    datos = datos[:,[0,2]] #Se cargan los canales 1 y 3\n",
        "    \n",
        "    # Calcular la media y la desviación estándar a lo largo del eje deseado (por ejemplo, eje 0)\n",
        "    media = np.mean(datos, axis=0)\n",
        "    desviacion_estandar = np.std(datos, axis=0)\n",
        "    \n",
        "    # Normalizar los datos utilizando z-score\n",
        "    datos_normalizados = (datos - media) / desviacion_estandar\n",
        "    \n",
        "    #Almacenar las matrices resultantes en una lista\n",
        "    matrices_normalizadas_train.append(datos_normalizados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFL-N1SDkano",
        "outputId": "521e6523-66d8-4877-9584-ff946d7c648a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(1920000, 2), (1920000, 2), (1920000, 2), (1920000, 2), (1920000, 2), (1920000, 2), (1920000, 2), (1920000, 2), (1920000, 2), (1920000, 2)]\n"
          ]
        }
      ],
      "source": [
        "#Se verifica que todas las matrices resultantes tengan los tamaños correspondientes\n",
        "def obtener_tamanos_matrices(lista_matrices):\n",
        "    tamanos = []\n",
        "    for matriz in lista_matrices:\n",
        "        tamanos.append(matriz.shape)\n",
        "    return tamanos\n",
        "\n",
        "tamanos = obtener_tamanos_matrices(matrices_normalizadas_train)\n",
        "print(tamanos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PxPj52DQm00-"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'tuple' object has no attribute 'shape'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m spectrogram_channel1 \u001b[39m=\u001b[39m signal\u001b[39m.\u001b[39mspectrogram(windowed_signals[:, \u001b[39m0\u001b[39m], fs\u001b[39m=\u001b[39m\u001b[39m2000\u001b[39m, nperseg\u001b[39m=\u001b[39mwindow_size, noverlap\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m(window_size \u001b[39m*\u001b[39m overlap))\n\u001b[0;32m     26\u001b[0m spectrogram_channel2 \u001b[39m=\u001b[39m signal\u001b[39m.\u001b[39mspectrogram(windowed_signals[:, \u001b[39m1\u001b[39m], fs\u001b[39m=\u001b[39m\u001b[39m2000\u001b[39m, nperseg\u001b[39m=\u001b[39mwindow_size, noverlap\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m(window_size \u001b[39m*\u001b[39m overlap))\n\u001b[1;32m---> 28\u001b[0m \u001b[39mprint\u001b[39m(spectrogram_channel1\u001b[39m.\u001b[39;49mshape)\n\u001b[0;32m     30\u001b[0m \u001b[39m# Asigna los espectrogramas de cada canal a la matriz tridimensional\u001b[39;00m\n\u001b[0;32m     31\u001b[0m stacked_gesture_spectrograms[i, :, \u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m spectrogram_channel1  \u001b[39m# Transpón el espectrograma\u001b[39;00m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
          ]
        }
      ],
      "source": [
        "# Crea una lista para almacenar los espectrogramas apilados de cada gesto\n",
        "stacked_spectrograms_train = []\n",
        "\n",
        "# Parámetros de la ventana deslizante\n",
        "window_size = 600  # Tamaño de la ventana deslizante\n",
        "overlap = 0.5  # Superposición entre ventanas (50%)\n",
        "\n",
        "for gesture_matrix in matrices_normalizadas_train:\n",
        "    # Obtén las dimensiones de los espectrogramas\n",
        "    num_spectrograms = int(np.floor((gesture_matrix.shape[0] - window_size) / (window_size * (1 - overlap)))) + 1\n",
        "    spectrogram_length = int(window_size / 2) + 1  # Longitud de los espectrogramas (la mitad de la ventana deslizante)\n",
        "\n",
        "    # Crea una matriz tridimensional para almacenar los espectrogramas apilados de un gesto\n",
        "    stacked_gesture_spectrograms = np.zeros((num_spectrograms, spectrogram_length, 2))\n",
        "\n",
        "    # Aplica ventanas deslizantes y calcula los espectrogramas\n",
        "    for i in range(num_spectrograms):\n",
        "        start = int(i * window_size * (1 - overlap))\n",
        "        end = start + window_size\n",
        "\n",
        "        # Aplica la ventana deslizante a las señales EMG\n",
        "        windowed_signals = gesture_matrix[start:end, :]\n",
        "\n",
        "        # Calcula los espectrogramas de cada canal\n",
        "        spectrogram_channel1 = signal.spectrogram(windowed_signals[:, 0], fs=2000, nperseg=window_size, noverlap=int(window_size * overlap))\n",
        "        spectrogram_channel2 = signal.spectrogram(windowed_signals[:, 1], fs=2000, nperseg=window_size, noverlap=int(window_size * overlap))\n",
        "\n",
        "        # Asigna los espectrogramas de cada canal a la matriz tridimensional\n",
        "        stacked_gesture_spectrograms[i, :, 0] = spectrogram_channel1  # Transpón el espectrograma\n",
        "        stacked_gesture_spectrograms[i, :, 1] = spectrogram_channel2\n",
        "\n",
        "    # Agrega la matriz apilada del gesto a la lista\n",
        "    stacked_spectrograms_train.append(stacked_gesture_spectrograms)\n",
        "\n",
        "# La lista stacked_spectrograms ahora contiene las matrices tridimensionales de los espectrogramas apilados de cada gesto\n",
        "# Cada elemento de la lista representa un gesto y tiene una forma (N, longitud_fija, 2), donde N es el número de espectrogramas y longitud_fija es la longitud común de los espectrogramas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8rbR0eZYnXI",
        "outputId": "2a3bb26d-cea5-437b-bd24-d2efa85d426e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(6399, 301, 2), (6399, 301, 2), (6399, 301, 2), (6399, 301, 2), (6399, 301, 2), (6399, 301, 2), (6399, 301, 2), (6399, 301, 2), (6399, 301, 2), (6399, 301, 2)]\n"
          ]
        }
      ],
      "source": [
        "#Se verifica que todas los espectrogramas tengan los tamaños correspondientes\n",
        "def obtener_tamanos_matrices(lista_matrices):\n",
        "    tamanos = []\n",
        "    for matriz in lista_matrices:\n",
        "        tamanos.append(matriz.shape)\n",
        "    return tamanos\n",
        "\n",
        "tamanos = obtener_tamanos_matrices(stacked_spectrograms_train)\n",
        "print(tamanos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pditGToEw6Z"
      },
      "outputs": [],
      "source": [
        "##############################Cargar las matrices por gesto TEST#######################################\n",
        "# Listado de nombres de archivos .mat que quieres cargar\n",
        "nombres_archivos = ['Reposo', 'Extension', 'Flexion','DesvCubital', 'DesvRadial', 'Agarre','Abduccion', 'Aduccion', 'Supinacion','Pronacion']\n",
        "matrices_normalizadas_test = []\n",
        "\n",
        "# Carga los archivos .mat y realiza la normalización de las matrices con z-score\n",
        "for nombre_archivo in nombres_archivos:\n",
        "    nombre_mat = nombre_archivo+'.mat'\n",
        "    ruta_archivo = os.path.join(pathTest, nombre_mat)  # Ruta completa del archivo\n",
        "    data = loadmat(ruta_archivo)\n",
        "    datos = data[nombre_archivo]\n",
        "    datos = datos[:,[0,2]] #Se cargan los canales 1 y 3\n",
        "    \n",
        "    # Calcular la media y la desviación estándar a lo largo del eje deseado (por ejemplo, eje 0)\n",
        "    media = np.mean(datos, axis=0)\n",
        "    desviacion_estandar = np.std(datos, axis=0)\n",
        "    \n",
        "    # Normalizar los datos utilizando z-score\n",
        "    datos_normalizados = (datos - media) / desviacion_estandar\n",
        "    \n",
        "    #Almacenar las matrices resultantes en una lista\n",
        "    matrices_normalizadas_test.append(datos_normalizados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qKokT2YE72h",
        "outputId": "b32a7502-cb98-42ed-b59c-edf533d04880"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(480000, 2), (480000, 2), (480000, 2), (480000, 2), (480000, 2), (480000, 2), (480000, 2), (480000, 2), (480000, 2), (480000, 2)]\n"
          ]
        }
      ],
      "source": [
        "#Se verifica que todas las matrices resultantes tengan los tamaños correspondientes\n",
        "def obtener_tamanos_matrices(lista_matrices):\n",
        "    tamanos = []\n",
        "    for matriz in lista_matrices:\n",
        "        tamanos.append(matriz.shape)\n",
        "    return tamanos\n",
        "\n",
        "tamanos = obtener_tamanos_matrices(matrices_normalizadas_test)\n",
        "print(tamanos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjfQ1JorFKfo"
      },
      "outputs": [],
      "source": [
        "# Crea una lista para almacenar los espectrogramas apilados de cada gesto\n",
        "stacked_spectrograms_test = []\n",
        "\n",
        "# Parámetros de la ventana deslizante\n",
        "window_size = 600  # Tamaño de la ventana deslizante\n",
        "overlap = 0.5  # Superposición entre ventanas (50%)\n",
        "\n",
        "for gesture_matrix in matrices_normalizadas_test:\n",
        "    # Obtén las dimensiones de los espectrogramas\n",
        "    num_spectrograms = int(np.floor((gesture_matrix.shape[0] - window_size) / (window_size * (1 - overlap)))) + 1\n",
        "    spectrogram_length = int(window_size / 2) + 1  # Longitud de los espectrogramas (la mitad de la ventana deslizante)\n",
        "\n",
        "    # Crea una matriz tridimensional para almacenar los espectrogramas apilados de un gesto\n",
        "    stacked_gesture_spectrograms = np.zeros((num_spectrograms, spectrogram_length, 2))\n",
        "\n",
        "    # Aplica ventanas deslizantes y calcula los espectrogramas\n",
        "    for i in range(num_spectrograms):\n",
        "        start = int(i * window_size * (1 - overlap))\n",
        "        end = start + window_size\n",
        "\n",
        "        # Aplica la ventana deslizante a las señales EMG\n",
        "        windowed_signals = gesture_matrix[start:end, :]\n",
        "\n",
        "        # Calcula los espectrogramas de cada canal\n",
        "        spectrogram_channel1 = signal.spectrogram(windowed_signals[:, 0], fs=2000, nperseg=window_size, noverlap=int(window_size * overlap))\n",
        "        spectrogram_channel2 = signal.spectrogram(windowed_signals[:, 1], fs=2000, nperseg=window_size, noverlap=int(window_size * overlap))\n",
        "\n",
        "        # Asigna los espectrogramas de cada canal a la matriz tridimensional\n",
        "        stacked_gesture_spectrograms[i, :, 0] = spectrogram_channel1[2].T  # Transpón el espectrograma\n",
        "        stacked_gesture_spectrograms[i, :, 1] = spectrogram_channel2[2].T\n",
        "\n",
        "    # Agrega la matriz apilada del gesto a la lista\n",
        "    stacked_spectrograms_test.append(stacked_gesture_spectrograms)\n",
        "\n",
        "# La lista stacked_spectrograms ahora contiene las matrices tridimensionales de los espectrogramas apilados de cada gesto\n",
        "# Cada elemento de la lista representa un gesto y tiene una forma (N, longitud_fija, 2), donde N es el número de espectrogramas y longitud_fija es la longitud común de los espectrogramas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-D1b9hNEJUVW",
        "outputId": "cd985ff5-a069-489d-efe6-04b26971aa20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(1599, 301, 2), (1599, 301, 2), (1599, 301, 2), (1599, 301, 2), (1599, 301, 2), (1599, 301, 2), (1599, 301, 2), (1599, 301, 2), (1599, 301, 2), (1599, 301, 2)]\n"
          ]
        }
      ],
      "source": [
        "#Se verifica que todas los espectrogramas tengan los tamaños correspondientes\n",
        "def obtener_tamanos_matrices(lista_matrices):\n",
        "    tamanos = []\n",
        "    for matriz in lista_matrices:\n",
        "        tamanos.append(matriz.shape)\n",
        "    return tamanos\n",
        "\n",
        "tamanos = obtener_tamanos_matrices(stacked_spectrograms_test)\n",
        "print(tamanos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3zX_iV1KOLm",
        "outputId": "b1ce71ec-1e46-499e-f758-eb22638c188a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensiones de X_train: (63990, 301, 2)\n",
            "Dimensiones de X_test: (15990, 301, 2)\n"
          ]
        }
      ],
      "source": [
        "# Apilar las matrices de espectrogramas en una sola matriz tridimensional para los datos de entrenamiento\n",
        "X_train = np.concatenate(stacked_spectrograms_train, axis=0)\n",
        "print(\"Dimensiones de X_train:\",X_train.shape)\n",
        "\n",
        "# Apilar las matrices de espectrogramas en una sola matriz tridimensional para los datos de prueba\n",
        "X_test = np.concatenate(stacked_spectrograms_test, axis=0)\n",
        "print(\"Dimensiones de X_test:\",X_test.shape)  # Verificar la forma de stacked_gestures_test\n",
        "\n",
        "T=X_train.shape[2]\n",
        "F=X_train.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycZAIqNKdhc-"
      },
      "outputs": [],
      "source": [
        "#seed = 42  # Set the desired seed value\n",
        "#np.random.seed(seed)  # Set the seed for random number generation\n",
        "#shape = X_train.shape\n",
        "#random_indices = np.random.permutation(shape[axis])\n",
        "#reordered_matrix = np.take(matrix, random_indices, axis=axis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Huy10XMUK4Hl",
        "outputId": "50213a8f-39b5-4036-fdd4-05ee728abe2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensiones de y_train: (63990, 10)\n",
            "Dimensiones de y_test: (15990, 10)\n"
          ]
        }
      ],
      "source": [
        "num_etiquetas = 10  # Número de etiquetas a asignar\n",
        "muestras_por_etiqueta_train = 6399  # Número de muestras por etiqueta train\n",
        "muestras_por_etiqueta_test = 1599  # Número de muestras por etiqueta test\n",
        "\n",
        "# Codificar las etiquetas en formato one-hot\n",
        "y_train = np.repeat(np.arange(num_etiquetas), muestras_por_etiqueta_train)\n",
        "y_train = to_categorical(y_train, num_etiquetas)\n",
        "\n",
        "y_test = np.repeat(np.arange(num_etiquetas), muestras_por_etiqueta_test)\n",
        "y_test = to_categorical(y_test, num_etiquetas)\n",
        "\n",
        "# Verificar las dimensiones de y_train y y_test\n",
        "print(\"Dimensiones de y_train:\", y_train.shape)\n",
        "print(\"Dimensiones de y_test:\", y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmLkxyULgg0-"
      },
      "outputs": [],
      "source": [
        "#### Dividir datos de entrenamiento en entrenamiento y validación\n",
        "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  0\n",
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 17613125891654613935\n",
            "xla_global_id: -1\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ8GJhioeG7j",
        "outputId": "ae847cad-7425-49d9-d889-9df0f6c18498"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"c:\\Users\\laura\\miniconda3\\envs\\TesisEnv\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\laura\\miniconda3\\envs\\TesisEnv\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\laura\\miniconda3\\envs\\TesisEnv\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\laura\\miniconda3\\envs\\TesisEnv\\Lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\laura\\miniconda3\\envs\\TesisEnv\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\laura\\miniconda3\\envs\\TesisEnv\\Lib\\site-packages\\keras\\engine\\input_spec.py\", line 235, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_1' (type Sequential).\n    \n    Input 0 of layer \"bidirectional_1\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 602)\n    \n    Call arguments received by layer 'sequential_1' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 301, 2), dtype=float32)\n      • training=True\n      • mask=None\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[17], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[39mreturn\u001b[39;00m accuracy\n\u001b[0;32m     28\u001b[0m \u001b[39m# Ejecutar la función objetivo sin optimización de hiperparámetros\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m mejor_resultado \u001b[39m=\u001b[39m objective()\n\u001b[0;32m     31\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMejor resultado:\u001b[39m\u001b[39m\"\u001b[39m, mejor_resultado)\n",
            "Cell \u001b[1;32mIn[17], line 20\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m modelo\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     18\u001b[0m es \u001b[39m=\u001b[39m EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m modelo\u001b[39m.\u001b[39;49mfit(X_train, y_train, validation_data\u001b[39m=\u001b[39;49m(X_test, y_test), epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[es], verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     22\u001b[0m y_pred \u001b[39m=\u001b[39m modelo\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     23\u001b[0m y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(y_pred, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\laura\\miniconda3\\envs\\TesisEnv\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filec47z9q23.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\laura\\miniconda3\\envs\\TesisEnv\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\laura\\miniconda3\\envs\\TesisEnv\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\laura\\miniconda3\\envs\\TesisEnv\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\laura\\miniconda3\\envs\\TesisEnv\\Lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\laura\\miniconda3\\envs\\TesisEnv\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\laura\\miniconda3\\envs\\TesisEnv\\Lib\\site-packages\\keras\\engine\\input_spec.py\", line 235, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_1' (type Sequential).\n    \n    Input 0 of layer \"bidirectional_1\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 602)\n    \n    Call arguments received by layer 'sequential_1' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 301, 2), dtype=float32)\n      • training=True\n      • mask=None\n"
          ]
        }
      ],
      "source": [
        "# Función objetivo para la optimización de hiperparámetros\n",
        "def objective():\n",
        "    units_lstm = 128\n",
        "    units_oculta = 128\n",
        "    dropout = 0.5\n",
        "\n",
        "    modelo = Sequential()\n",
        "    # modelo.add(Flatten())\n",
        "    modelo.add(Bidirectional(LSTM(units=units_lstm, return_sequences=True)))\n",
        "    modelo.add(BatchNormalization())\n",
        "    modelo.add(Dropout(dropout))\n",
        "    modelo.add(TimeDistributed(Dense(units=units_oculta, activation='relu')))\n",
        "    modelo.add(Flatten())\n",
        "    modelo.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "    modelo.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    es = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "    modelo.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=64, callbacks=[es], verbose=0)\n",
        "\n",
        "    y_pred = modelo.predict(X_test)\n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "    accuracy = accuracy_score(np.argmax(y_test, axis=1), y_pred)\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Ejecutar la función objetivo sin optimización de hiperparámetros\n",
        "mejor_resultado = objective()\n",
        "\n",
        "print(\"Mejor resultado:\", mejor_resultado)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "H29UtuIEhNNc"
      },
      "source": [
        "Configuración del PC para correr en local\n",
        "\n",
        "Shuffle \n",
        "\n",
        "Hiperparámetros"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
